---
title: "Ensemble Learning"
author: "Yuling Hsu"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
##Load package
```{r}
library(caret)
library(tidyverse)
```

## Building ensemble of your own
In this classroom exercise, you will create an ensemble of your own. That is, you will first create individual models and then combine them. Specifically, you will learn that all individual model don't have to be of same type, and you will also learn several methods to combine these models.

Load brest cancer data: wisc_bc_data.csv
Data Description - This data is about brest cancer diagnostics: https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)

```{r}
wbcd <- read.csv("wisc_bc_data.csv")
wbcd %>%
  glimpse()
```

Note: In all these questions you need to predict "diagnosis" variable.

Q.1 Remove ID variable from the data
```{r}
-which(colnames(wbcd) %in% c("id"))
head(wbcd)
```

Q.2. Use factor() to replace "B" and "M" by "Benign" and "Malignant" respectively in variable "diagnosis". 
Hint: Use levels = c("B", "M") and labels = c("Benign", "Malignant") in the factor() function
```{r}
wbcd$diagnosis <-
  factor(x = wbcd$diagnosis, levels = c("B", "M"), labels = c("Benign", "Malignant"))

head(wbcd)
```

Partition data: 60/40
```{r}
set.seed(1)
train_rows <- sample(row.names(wbcd), length(wbcd$area_mean)*0.6)
test_rows <- setdiff(row.names(wbcd), train_rows)
train_data <- wbcd[train_rows,]
test_data <- wbcd[test_rows,]
head(test_data)
```

Q.3a. Train a knn model: Use train() function with method="knn" for knn
```{r}
mod01 <- train(diagnosis ~., method="knn", data = train_data, preProcess = c("center", "scale"))
```

Q.3b. Predict using knn model. Use predict() function for this. Use type = "raw".
```{r}
pred_mod01 <- predict(mod01, newdata = test_data, type = "raw")
```

Q.3c. Obtain confusion matrix using confusionMatrix(prediction, truth)
```{r}
confusionMatrix(pred_mod01, test_data$diagnosis)
```

Q.4a. Training Decision Tree using train() function with method="rpart"
```{r}
mod02 <- train(diagnosis ~., method="rpart", data = train_data, preProcess = c("center", "scale"))
```

Q.4b. Predicting using Decision Tree model. Use type = "raw".
```{r}
pred_mod02 <- predict(mod02, newdata = test_data, type = "raw")
```

Q.4c. Obtain confusionMatrix(prediction, truth)
```{r}
confusionMatrix(pred_mod02, test_data$diagnosis)
```

Q.5a. Training the logistic model train(x,y,method='glm')
```{r}
mod03 <- 
  train(
    diagnosis ~ radius_mean,
    data = train_data,
    method = 'glm'
  )
```

Q.5b. Predict using logistic
```{r}
pred_mod03 <- 
  predict(mod03, test_data)
```

Q.5c. Obtain confusionMatrix(prediction, truth)
```{r}
confusionMatrix(pred_mod03, test_data$diagnosis)
```


Q.6a. Predict classification probabilities for knn, dection tree, and logistic models
Hint: Use type = "prob" in the predict() function.
```{r}
library(caret)

# Train the k-NN model
knn_model <- train(diagnosis ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))
# Predict probabilities for the test set
knn_prob <- predict(knn_model, newdata = test_data, type = "prob")

# Train the decision tree model
tree_model <- train(diagnosis ~ ., data = train_data, method = "rpart", trControl = trainControl(method = "cv"))
# Predict probabilities for the test set
tree_prob <- predict(tree_model, newdata = test_data, type = "prob")

# Train the logistic regression model
logit_model <- train(diagnosis ~ radius_mean, data = train_data, method = "glm", family = "binomial")
# Predict probabilities for the test set
logit_prob <- predict(logit_model, newdata = test_data, type = "prob")

```


Q.6b. Compute the average of classification probabilities (for Benign class) from above three models (knn, dection tree, and logistic).
```{r}
knn_benign_prob <- knn_prob[, "Benign"]
tree_benign_prob <- tree_prob[, "Benign"]
logit_benign_prob <- logit_prob[, "Benign"]
average_benign_prob <- rowMeans(cbind(knn_benign_prob, tree_benign_prob, logit_benign_prob))
head(average_benign_prob)
test_data$avg_benign_prob <- average_benign_prob
```

Q.6c. Predict as "Benign" if Avg_Prob>0.5 otherwise as "Malignant"
```{r}
test_data$Prediction<-as.factor(ifelse(test_data$avg_benign_prob > 0.5, "Benign", "Malignant"))
```


Q.6d. Obtain confusionMatrix(prediction, truth)
```{r}
confusionMatrix(test_data$Prediction, test_data$diagnosis)
knn_prob_1 <- test_data$Prediction
```

Q.7a. Take weighted average (weighted by model accuracies) to create ensembles.
Hint: Use a code similar to the below code to obtain accuracies of different models.
confusion_logistic <- confusionMatrix(pred_logistic, test_data$diagnosis)
logistic_accuracy <- confusion_logistic$overall['Accuracy']
```{r}
#knn
confusion_knn <- confusionMatrix(pred_mod01, test_data$diagnosis)
knn_accuracy <- confusion_knn$overall['Accuracy']
knn_accuracy
#decision tree
confusion_tree <- confusionMatrix(pred_mod02, test_data$diagnosis)
tree_accuracy <- confusion_tree$overall['Accuracy']
tree_accuracy
#logic regression
confusion_logistic <- confusionMatrix(pred_mod03, test_data$diagnosis)
logistic_accuracy <- confusion_logistic$overall['Accuracy']
logistic_accuracy
#get weights
weights <- c(knn_accuracy, tree_accuracy, logistic_accuracy) / sum(c(knn_accuracy, tree_accuracy, logistic_accuracy))

Wtd_Avg_prob <- weights[1]*logit_prob + weights[2]*tree_prob + weights[3]*knn_benign_prob

Wtd_Avg_prob$Prediction<-as.factor(ifelse(Wtd_Avg_prob$Benign > 0.5, "Benign", "Malignant"))
```

Q.7b. Predict as "Benign" if Wtd_Avg_prob>0.5 otherwise as "Malignant"
```{r}
Wtd_Avg_prob$Prediction<-as.factor(ifelse(Wtd_Avg_prob$Benign > 0.5, "Benign", "Malignant"))
head(Wtd_Avg_prob)
```

Q.7c. Obtain confusionMatrix(prediction, truth) for prediction using Weighted Average
```{r}
confusionMatrix(Wtd_Avg_prob$Prediction, test_data$diagnosis)
```


Q.8. Instead of taking average of proabilities, use majority vote to predict
Predict class instead of probability, and convert the class into 0/1 values
Hint: Convert prediction into 0/1 binary votes and then add votes by different models. Then, predict "Benign" if the number of votes for Benign are >= 2. 
```{r}
knn_pred <- predict(knn_model, newdata = test_data)
dt_pred <- predict(tree_model, newdata = test_data)
logistic_pred <- predict(logit_model, newdata = test_data)

knn_votes <- ifelse(knn_pred == "Benign", 1, 0)
dt_votes <- ifelse(dt_pred == "Benign", 1, 0)
logistic_votes <- ifelse(logit_prob == "Benign", 1, 0)
fc
```

Q.8a. Add the votes
```{r}
# Add votes by different models
add_lists <- function(x, y) {
  return(x + y)
}
total_votes <- mapply(add_lists, knn_votes, dt_votes)

print(total_votes)

```

Q.8b. Predict using majority rule.
```{r}
# predict "Benign" if the number of votes for "Benign" is >= 2
pred_majority_vote <- as.factor(ifelse(total_votes >= 2, "Benign", "Malignant"))
# convert the predicted class into 0/1 values
pred_majority_vote_number <- as.factor(ifelse(pred_majority_vote == "Benign", 0, 1))
head(pred_majority_vote_number)
head(pred_majority_vote)
```

Q.9. Does ensembling increase accuracy? Which ensembling methods is more accurate, simple averaging, weighted-averaging, or majority-vote?
Hint: Compare all these accuracies using confusionMatrix()
simple averaging is more accurate, more than 95% accurate which is so high.
```{r}
confusionMatrix(test_data$Prediction, test_data$diagnosis)
confusionMatrix(Wtd_Avg_prob$Prediction, test_data$diagnosis)
confusionMatrix(pred_majority_vote, test_data$diagnosis)
```

